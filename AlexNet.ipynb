{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "gwTKNU0i_M_A",
    "outputId": "0c9e1175-23f8-4970-95ec-1dbce703270e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 19 17:54:28 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8    15W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "4E8W1-dn_Qy5",
    "outputId": "a0ce82a2-588f-4f64-e18e-7c5c88222760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet-cu100mkl in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100mkl) (2.21.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100mkl) (1.16.4)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100mkl) (0.8.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100mkl) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100mkl) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100mkl) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100mkl) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu100mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fs2zA7y7AG4W"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mxnet import nd, gluon, autograd, init, context\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYgZdLpGG_Gy"
   },
   "outputs": [],
   "source": [
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"A utility function to set matplotlib axes\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend: axes.legend(legend)\n",
    "    axes.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYU24W3RGzFz"
   },
   "outputs": [],
   "source": [
    "class Animator(object):\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=[], xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear', fmts=None,\n",
    "                 nrows=1, ncols=1, figsize=(3.5, 2.5)):\n",
    "        \"\"\"Incrementally plot multiple lines.\"\"\"\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1: self.axes = [self.axes,]\n",
    "        # use a lambda to capture arguments\n",
    "        self.config_axes = lambda : set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        \"\"\"Add multiple data points into the figure.\"\"\"\n",
    "        if not hasattr(y, \"__len__\"): y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"): x = [x] * n\n",
    "        if not self.X: self.X = [[] for _ in range(n)]\n",
    "        if not self.Y: self.Y = [[] for _ in range(n)]\n",
    "        if not self.fmts: self.fmts = ['-'] * n\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvvCfpNCARyt"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, resize):\n",
    "  transformer = transforms.Compose([\n",
    "      transforms.Resize(resize),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "  train = gluon.data.vision.datasets.FashionMNIST(train=True)\n",
    "  train = train.transform_first(transformer)\n",
    "  train_iter = gluon.data.DataLoader(train, batch_size, shuffle=True, num_workers=4)\n",
    "  test = gluon.data.vision.datasets.FashionMNIST(train=False)\n",
    "  test = test.transform_first(transformer)\n",
    "  test_iter = gluon.data.DataLoader(test, batch_size, shuffle=False, num_workers=4)\n",
    "  return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlwWl3iHBzz2"
   },
   "outputs": [],
   "source": [
    "def show_images(X, nrows, ncols):\n",
    "  _, axes = plt.subplots(nrows, ncols)\n",
    "  axes = axes.flatten()\n",
    "  for img, ax in zip(X, axes):\n",
    "    ax.imshow(img)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "  return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQIrmZlTFoav"
   },
   "outputs": [],
   "source": [
    "def eval_acc(net, data_iter, ctx):\n",
    "  acc = 0\n",
    "  size = 0\n",
    "  for X, y in data_iter:\n",
    "    X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "    result = net(X).softmax(axis=1).argmax(axis=1)\n",
    "    acc += (result == y.astype('float32')).sum().asscalar()\n",
    "    size += len(y)\n",
    "  return acc / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTeAaipJGLWL"
   },
   "outputs": [],
   "source": [
    "def eval_loss(net, data_iter, loss, ctx):\n",
    "  l = 0\n",
    "  size = 0\n",
    "  for X, y in data_iter:\n",
    "    X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "    l += loss(net(X), y).sum().asscalar()\n",
    "    size += len(y)\n",
    "  return l / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-0fufN1CtYR"
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AlexNet, self).__init__(**kwargs)\n",
    "        self.conv1 = nn.Conv2D(channels=96, kernel_size=11, strides=4, activation='relu')\n",
    "        self.pool2 = nn.MaxPool2D(pool_size=3, strides=2)\n",
    "        self.conv3 = nn.Conv2D(channels=256, kernel_size=5, padding=2, activation='relu')\n",
    "        self.pool4 = nn.MaxPool2D(pool_size=3, strides=2)\n",
    "        self.conv5 = nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu')\n",
    "        self.conv6 = nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu')\n",
    "        self.conv7 = nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu')\n",
    "        self.pool8 = nn.MaxPool2D(pool_size=3, strides=2)\n",
    "        self.dense9 = nn.Dense(4096, activation='relu')\n",
    "        self.dropout10 = nn.Dropout(0.5)\n",
    "        self.dense11 = nn.Dense(4096, activation='relu')\n",
    "        self.dropout12 = nn.Dropout(0.5)\n",
    "        self.dense13 = nn.Dense(10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "#         print(self.conv1.name, x.shape)\n",
    "        x = self.pool2(x)\n",
    "#         print(self.pool2.name, x.shape)\n",
    "        x = self.conv3(x)\n",
    "#         print(self.conv3.name, x.shape)\n",
    "        x = self.pool4(x)\n",
    "#         print(self.pool4.name, x.shape)\n",
    "        x = self.conv5(x)\n",
    "#         print(self.conv5.name, x.shape)\n",
    "        x = self.conv6(x)\n",
    "#         print(self.conv6.name, x.shape)\n",
    "        x = self.conv7(x)\n",
    "#         print(self.conv7.name, x.shape)\n",
    "        x = self.pool8(x)\n",
    "#         print(self.pool8.name, x.shape)\n",
    "        x = self.dense9(x)\n",
    "#         print(self.dense9.name, x.shape)\n",
    "        x = self.dropout10(x)\n",
    "        x = self.dense11(x)\n",
    "#         print(self.dense11.name, x.shape)\n",
    "        x = self.dropout12(x)\n",
    "        x = self.dense13(x)\n",
    "#         print(self.dense13.name, x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "cEuP2gtqE-Io",
    "outputId": "8527c49a-b99f-4312-a1f3-6b8d45b457d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.09371628 -0.062374   -0.05596989  0.15733346  0.01311133 -0.09858255\n",
       "  -0.00832834 -0.10987963 -0.04330236 -0.03168843]]\n",
       "<NDArray 1x10 @gpu(0)>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "resize = 224\n",
    "train_iter, test_iter = get_dataloader(batch_size, resize)\n",
    "\n",
    "ctx = context.gpu()\n",
    "net = AlexNet()\n",
    "net.initialize(init=init.Xavier(), ctx=ctx)\n",
    "testX = nd.random.normal(shape=(1, 1, 224, 224), ctx=ctx)\n",
    "net(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "V1p3_n6IFCTI",
    "outputId": "2313041e-444e-4ab5-c569-64cf7241bb97"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5bf45e63667d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0manimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-b72b05a083d8>\u001b[0m in \u001b[0;36meval_acc\u001b[0;34m(net, data_iter, ctx)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1994\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1997\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPIAAAC4CAYAAADZq7GuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2ZgUYEE2JgVYkI1JARZkY1LA/wPCDlvK6wbygwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.001})\n",
    "\n",
    "epochs = 100\n",
    "animator = Animator(xlabel='epochs', xlim=[0, epochs], legend=['loss', 'acc'])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for X, y in train_iter:\n",
    "    X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "    with autograd.record():\n",
    "      l = loss(net(X), y)\n",
    "    l.backward()\n",
    "    trainer.step(batch_size)\n",
    "  epoch_acc = eval_acc(net, test_iter, ctx)\n",
    "  epoch_loss = eval_loss(net, test_iter, loss, ctx)\n",
    "  animator.add(epoch, (epoch_loss, epoch_acc))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bFZBMlsEU6B"
   },
   "outputs": [],
   "source": [
    "for X, y in train_iter:\n",
    "  print(X.shape)\n",
    "  print(y.shape)\n",
    "  show_images(X.squeeze(axis=1).asnumpy(), 2, 5)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzVfkUjVAtR3"
   },
   "outputs": [],
   "source": [
    "gluon.data.vision.datasets.FashionMNIST.transform_first?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AlexNet",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
